<h1>NF_EmotionTrackingVR</h1>

NF_EmotionTrackingVR is a Unity application that can recognize seven facial expressions (Happiness, Anger, Surprise, Sadness, Fear, Contempt, Disgust), using a VR visor with facial tracking sensors. After recognizing the chosen expression, a dictionary containing the pairs formed by (expression, associated numeric value) is saved in a json file. The present expressions where choosen accordingly to the Paul Ekman's Facial Action Coding System (FACS).

<h1>Repository content</h1>
<b>Unity folder</b></br>
&ensp;&ensp;&ensp;test_VR_NF: the unity project folder</br>
&ensp;&ensp;&ensp;TODO inserire unitypackage: the unitypackage file to import the project</br>
&ensp;&ensp;&ensp;TODO inserire file json: a json sample file of facial tracking data extracted during experimentation</br>

<h1>Requirements and installation for the Unity project</h1>

* <b>Unity game engine</b>, preferably 2022.3.2f1.</br>

* <a href="https://www.meta.com/en-gb/help/quest/articles/headsets-and-accessories/oculus-rift-s/install-app-for-link/"><b>Oculus desktop app</b></a>, follow steps in this page.</br>

* <b>Download Meta Quest mobile app</b></br>

* <a href="https://developer.oculus.com/downloads/package/oculus-developer-hub-win"><b>Meta Quest Developer App</b></a></br>

* Create a Meta account and a Meta Oculus Developer account</br>

* Activate developer mode both in mobile app and VR visor</br>

* <b>Follow steps in this <a href="https://developer.oculus.com/documentation/unity/unity-tutorial-hello-vr/">page</a></b>, then in Build Settings > Android > Texture Compression, set ASTC</br>

* Make sure that you activated face and hands tracking in VR visor settings

* Download the unitypackage from this repository and import it in the project you created in previous step and start you experiments!


<h1>Installation for standalone apk</h1>

* Make sure that you activated face and hands tracking in VR visor settings

* Just load it in the VR visor and run it









